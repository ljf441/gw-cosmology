{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljf/dis/bns/lib/python3.12/site-packages/gwpy/time/__init__.py:36: UserWarning: Wswiglal-redir-stdio:\n",
      "\n",
      "SWIGLAL standard output/error redirection is enabled in IPython.\n",
      "This may lead to performance penalties. To disable locally, use:\n",
      "\n",
      "with lal.no_swig_redirect_standard_output_error():\n",
      "    ...\n",
      "\n",
      "To disable globally, use:\n",
      "\n",
      "lal.swig_redirect_standard_output_error(False)\n",
      "\n",
      "Note however that this will likely lead to error messages from\n",
      "LAL functions being either misdirected or lost when called from\n",
      "Jupyter notebooks.\n",
      "\n",
      "To suppress this warning, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
      "import lal\n",
      "\n",
      "  from lal import LIGOTimeGPS\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import bilby\n",
    "import pandas as pd\n",
    "from gwpy.timeseries import TimeSeries\n",
    "import scipy\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.patches import Circle\n",
    "import dynesty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 4\n",
    "sampling_frequency = 2048\n",
    "t0_gps = 1126259460.4\n",
    "n_samples = duration*sampling_frequency\n",
    "time = np.linspace(0, duration, n_samples)\n",
    "\n",
    "delta = 5\n",
    "ras = np.radians(np.arange(0, 360, delta))\n",
    "decs = np.radians(np.arange(-90, 90, delta))\n",
    "ra_s = np.radians(np.linspace(-180, 180, len(ras)+1))\n",
    "dec_s = np.radians(np.linspace(-90, 90, len(decs)+1))\n",
    "radec_s = np.array([(ra, dec) for ra in ra_s for dec in dec_s])\n",
    "radec = np.array([(ra, dec) for ra in ras for dec in decs])\n",
    "radec_map = radec.reshape(36, 72, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_complex(df, col):\n",
    "    df[f'{col}'] = np.array(df[f'{col}'].values, dtype=complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "complex() arg is a malformed string",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m l1_psd = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata/L1_psd_2.txt\u001b[39m\u001b[33m'\u001b[39m, sep=\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m v1_psd = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata/V1_psd_2.txt\u001b[39m\u001b[33m'\u001b[39m, sep=\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mcast_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mh+\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m cast_complex(waveform, \u001b[33m'\u001b[39m\u001b[33mhx\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m cast_complex(h1_strain, \u001b[33m'\u001b[39m\u001b[33mh\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mcast_complex\u001b[39m\u001b[34m(df, col)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcast_complex\u001b[39m(df, col):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     df[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m] = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcol\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcomplex\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: complex() arg is a malformed string"
     ]
    }
   ],
   "source": [
    "waveform = pd.read_csv('data/waveform_2.txt', sep=' ')\n",
    "h1_strain = pd.read_csv('data/H1_strain_2.txt', sep=' ')\n",
    "l1_strain = pd.read_csv('data/L1_strain_2.txt', sep=' ')\n",
    "v1_strain = pd.read_csv('data/V1_strain_2.txt', sep=' ')\n",
    "h1_psd = pd.read_csv('data/H1_psd_2.txt', sep=' ')\n",
    "l1_psd = pd.read_csv('data/L1_psd_2.txt', sep=' ')\n",
    "v1_psd = pd.read_csv('data/V1_psd_2.txt', sep=' ')\n",
    "\n",
    "cast_complex(waveform, 'h+')\n",
    "cast_complex(waveform, 'hx')\n",
    "cast_complex(h1_strain, 'h')\n",
    "cast_complex(l1_strain, 'h')\n",
    "cast_complex(v1_strain, 'h')\n",
    "cast_complex(h1_strain, 'white')\n",
    "cast_complex(l1_strain, 'white')\n",
    "cast_complex(v1_strain, 'white')\n",
    "\n",
    "strain_dfs = [h1_strain, l1_strain, v1_strain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFOH = bilby.gw.detector.InterferometerList(['H1'])[0]\n",
    "IFOH.power_spectral_density = bilby.gw.detector.PowerSpectralDensity(frequency_array=h1_psd['Hz'].values, psd_array=h1_psd['PSD'].values)\n",
    "# IFOH.frequency_array = h1_psd['Hz']\n",
    "\n",
    "IFOL = bilby.gw.detector.InterferometerList(['L1'])[0]\n",
    "IFOL.power_spectral_density = bilby.gw.detector.PowerSpectralDensity(frequency_array=l1_psd['Hz'].values, psd_array=l1_psd['PSD'].values)\n",
    "# IFOL.frequency_array = l1_psd['Hz']\n",
    "\n",
    "IFOV = bilby.gw.detector.InterferometerList(['V1'])[0]\n",
    "IFOV.power_spectral_density = bilby.gw.detector.PowerSpectralDensity(frequency_array=v1_psd['Hz'].values, psd_array=v1_psd['PSD'].values)\n",
    "# IFOV.frequency_array = v1_psd['Hz']\n",
    "\n",
    "IFOS = [IFOH, IFOL, IFOV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:24 bilby INFO    : Running for label 'custom_likelihood', output will be saved to 'outdir'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     36\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m log_likelihood(\u001b[38;5;28mself\u001b[39m.data_dfs, \u001b[38;5;28mself\u001b[39m.waveform, \u001b[38;5;28mself\u001b[39m.IFOS)\n\u001b[32m     38\u001b[39m gwl = Likelihood(data_dfs=[h1_strain, l1_strain, v1_strain], waveform=waveform, IFOS=[IFOH, IFOL, IFOV])\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m result = \u001b[43mbilby\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_sampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgwl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpriors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdynesty\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnlive\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrwalk\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcustom_likelihood\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     47\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dis/bns/lib/python3.12/site-packages/bilby/core/sampler/__init__.py:248\u001b[39m, in \u001b[36mrun_sampler\u001b[39m\u001b[34m(likelihood, priors, label, outdir, sampler, use_ratio, injection_parameters, conversion_function, plot, default_priors_file, clean, meta_data, save, gzip, result_class, npool, **kwargs)\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInput priors not understood should be dict or PriorDict\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[43mpriors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_priors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_priors_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_priors_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# Generate the meta-data if not given and append the likelihood meta_data\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m meta_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dis/bns/lib/python3.12/site-packages/bilby/core/prior/dict.py:347\u001b[39m, in \u001b[36mPriorDict.fill_priors\u001b[39m\u001b[34m(self, likelihood, default_priors_file)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[33;03mFill dictionary of priors based on required parameters of likelihood\u001b[39;00m\n\u001b[32m    323\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    342\u001b[39m \n\u001b[32m    343\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;28mself\u001b[39m.convert_floats_to_delta_functions()\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m missing_keys = \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m - \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m.keys())\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m missing_key \u001b[38;5;129;01min\u001b[39;00m missing_keys:\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.test_redundancy(missing_key):\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "prior = bilby.core.prior.PriorDict()\n",
    "prior['geocent_time'] = bilby.core.prior.Uniform(name=\"geocent_time\", minimum=t0_gps-0.1, maximum=t0_gps+0.1, unit='s')\n",
    "prior['luminosity_distance'] = bilby.core.prior.Uniform(name=\"luminosity_distance\", minimum=1, maximum=1000, unit='Mpc')\n",
    "prior['ra'] = bilby.core.prior.Uniform(name=\"ra\", minimum=0, maximum=2 * np.pi, unit='rad', boundary='periodic')\n",
    "prior['dec'] = bilby.core.prior.Uniform(name=\"dec\", minimum=-np.pi/2, maximum=np.pi/2, unit='rad', boundary='reflective')\n",
    "prior['psi'] = bilby.core.prior.Uniform(name=\"psi\", minimum=0, maximum=np.pi, unit='rad', boundary='periodic')\n",
    "\n",
    "def log_likelihood(params, data_dfs, waveform, IFOS):\n",
    "    DL = params['luminosity_distance']\n",
    "    ra = params['ra']\n",
    "    dec = params['dec']\n",
    "    psi = params['psi']\n",
    "    tc_geo = params['geocent_time']\n",
    "    logl = 0\n",
    "\n",
    "    for strain, IFO in zip(data_dfs, IFOS):\n",
    "        fplus = IFO.antenna_response(ra, dec, tc_geo, psi, 'plus')\n",
    "        fcross = IFO.antenna_response(ra, dec, tc_geo, psi, 'cross')\n",
    "        template = waveform['h+'].values * fplus + waveform['hx'].values * fcross\n",
    "        delay = IFO.time_delay_from_geocenter(ra, dec, tc_geo)\n",
    "        h = template * np.exp(-1j * 2 * np.pi * waveform['Hz'].values * delay)\n",
    "        h /= DL\n",
    "        res = strain['h'] - h\n",
    "        logl -= 0.5 * np.sum(np.conj(res)*res / IFO.power_spectral_density.psd_array.real)\n",
    "\n",
    "    return logl\n",
    "\n",
    "class Likelihood(bilby.core.likelihood.Likelihood):\n",
    "    def __init__(self, data_dfs, waveform, IFOS):\n",
    "        super().__init__()\n",
    "        self.data_dfs = data_dfs\n",
    "        self.waveform = waveform\n",
    "        self.IFOS = IFOS\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        return log_likelihood(self.data_dfs, self.waveform, self.IFOS)\n",
    "\n",
    "gwl = Likelihood(data_dfs=[h1_strain, l1_strain, v1_strain], waveform=waveform, IFOS=[IFOH, IFOL, IFOV])\n",
    "\n",
    "result = bilby.run_sampler(\n",
    "    likelihood=gwl,\n",
    "    priors=prior,\n",
    "    sampler='dynesty',\n",
    "    nlive=10,\n",
    "    sample='rwalk',\n",
    "    label='custom_likelihood'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def priors(u):\n",
    "    tc_geo = u[0] * (t0_gps + 0.1 - (t0_gps - 0.1)) + (t0_gps - 0.1)\n",
    "    DL = u[1] * (1000 - 1) + 1\n",
    "    ra = u[2] * (2 * np.pi - 0) + 0\n",
    "    dec = u[3] * (np.pi/2 - (-np.pi/2)) + (-np.pi/2)\n",
    "    psi = u[4] * (np.pi - 0) + 0\n",
    "    return np.array([tc_geo, DL, ra, dec, psi])\n",
    "\n",
    "def log_likelihood(params):\n",
    "    tc_geo = params[0]\n",
    "    DL = params[1]\n",
    "    ra = params[2]\n",
    "    dec = params[3]\n",
    "    psi = params[4]\n",
    "    logl = 0\n",
    "\n",
    "    for strain, IFO in zip(data_dfs, IFOS):\n",
    "        fplus = IFO.antenna_response(ra, dec, tc_geo, psi, 'plus')\n",
    "        fcross = IFO.antenna_response(ra, dec, tc_geo, psi, 'cross')\n",
    "        template = waveform['h+'].values * fplus + waveform['hx'].values * fcross\n",
    "        delay = IFO.time_delay_from_geocenter(ra, dec, tc_geo)\n",
    "        h = template * np.exp(-1j * 2 * np.pi * waveform['Hz'].values * delay)\n",
    "        h /= DL\n",
    "        res = strain['h'] - h\n",
    "        logl -= 0.5 * np.sum(np.conj(res)*res / IFO.power_spectral_density.psd_array.real)\n",
    "\n",
    "    return logl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_iso = dynesty.NestedSampler(isoll, prior_transform_iso, 21, nlive = 2000, sample = 'rwalk')\n",
    "sampler_iso.run_nested(dlogz=0.01, print_progress=True)\n",
    "res_iso = sampler_iso.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
